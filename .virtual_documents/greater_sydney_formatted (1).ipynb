





# import all the necessary libraries
import pandas as pd
import geopandas as gpd
from pathlib import Path
import os
import requests
import time
import json
from shapely.geometry import Point, Polygon, shape
from shapely.ops import transform
import pyproj
from functools import partial
from sqlalchemy import create_engine, text
from sqlalchemy.types import Text
import warnings





# credentials file path
CREDENTIALS_FILE = "Credentials.json"

# connect to postgresql database using the credentials from json file
def pgconnect(credential_filepath, db_schema="public"):
    """connect to postgresql database using credentials from json file"""
    with open(credential_filepath) as f:
        db_conn_dict = json.load(f)
        host = db_conn_dict['host']
        db_user = db_conn_dict['user']
        db_pw = db_conn_dict['password']
        default_db = db_conn_dict['user']
        try:
            db = create_engine('postgresql+psycopg2://'+db_user+':'+db_pw+'@'+host+'/'+default_db, echo=False)
            conn = db.connect()
            print('connected successfully.')
        except Exception as e:
            print("unable to connect to the database.")
            print(e)
            db, conn = None, None
        return db, conn





# define a function to clean the income dataset
def clean_income(df):
    """clean and process income data"""
    df_renamed = df.rename(columns={"sa2_code21": "sa2_code"})
    df_copy = df_renamed[["sa2_code", "sa2_name", "median_income", "mean_income"]].copy()
    df_copy["sa2_code"] = df_copy["sa2_code"].astype(str)
    df_copy["median_income"] = pd.to_numeric(df_copy["median_income"], errors="coerce")
    df_copy["mean_income"] = pd.to_numeric(df_copy["mean_income"], errors="coerce")
    return df_copy

# define a function to clean the population dataset
def clean_population(df):
    """clean and process population data"""
    df_renamed = df.rename(columns={
        "0-4_people": "age_0_4",
        "5-9_people": "age_5_9",
        "10-14_people": "age_10_14",
        "15-19_people": "age_15_19",
        "20-24_people": "age_20_24",
        "25-29_people": "age_25_29",
        "30-34_people": "age_30_34",
        "35-39_people": "age_35_39",
        "40-44_people": "age_40_44",
        "45-49_people": "age_45_49",
        "50-54_people": "age_50_54",
        "55-59_people": "age_55_59",
        "60-64_people": "age_60_64",
        "65-69_people": "age_65_69",
        "70-74_people": "age_70_74",
        "75-79_people": "age_75_79",
        "80-84_people": "age_80_84",
        "85-and-over_people": "age_85_plus",
        "total_people": "total_population"
    })
    df_renamed["sa2_code"] = df_renamed["sa2_code"].astype(str)
    pop_cols = [col for col in df_renamed.columns if col.startswith("age_") or col == "total_population"]
    df_copy = df_renamed.copy()
    for col in pop_cols:
        df_copy[col] = pd.to_numeric(df_copy[col], errors="coerce").fillna(0).astype(int)
    return df_copy[["sa2_code", "sa2_name"] + pop_cols]

# create a function to clean the business dataset
def clean_businesses(df):
    """clean and process business data"""
    df_copy = df[[
        "sa2_code", "sa2_name", "industry_code", "industry_name", "total_businesses"
    ]].copy()
    df_copy["sa2_code"] = df_copy["sa2_code"].astype(str)
    df_copy["total_businesses"] = pd.to_numeric(df_copy["total_businesses"], errors="coerce").fillna(0).astype(int)
    return df_copy

# create a functions to clean the stops dataset 
# assumes the stops.txt has been renamed to stops.csv
def clean_stops(df):
    """clean and process transport stops data"""
    df_copy = df[["stop_id", "stop_name", "stop_lat", "stop_lon"]].copy()
    df_copy["stop_lat"] = pd.to_numeric(df_copy["stop_lat"], errors="coerce")
    df_copy["stop_lon"] = pd.to_numeric(df_copy["stop_lon"], errors="coerce")
    return df_copy.dropna(subset=["stop_lat", "stop_lon"])

# create a function to clean the shapefiles for the schools
def clean_catchments(file_path):
    """clean and process school catchment data"""
    gdf = gpd.read_file(file_path)
    if 'USE_DESC' in gdf.columns:
        gdf = gdf.rename(columns={"USE_DESC": "school_name"})
    else:
        base_name = Path(file_path).stem
        gdf['school_name'] = f"{base_name}_catchment"
    
    gdf = gdf[[col for col in gdf.columns if col in ['school_name', 'geometry']]]
    
    if gdf.crs is not None and gdf.crs.to_epsg() != 4326:
        gdf = gdf.to_crs(epsg=4326)
    elif gdf.crs is None:
        gdf.set_crs(epsg=4326, inplace=True)
    return gdf

# create a function to clean the sa2 boundaries dataset
def clean_sa2_boundaries(file_path):
    """clean and process sa2 boundaries data"""
    gdf = gpd.read_file(file_path)
    gdf = gdf[gdf["GCC_NAME21"] == "Greater Sydney"].copy()
    gdf = gdf[["SA2_CODE21", "SA2_NAME21", "geometry"]].rename(columns={
        "SA2_CODE21": "sa2_code",
        "SA2_NAME21": "sa2_name"
    })
    gdf['sa2_code'] = gdf['sa2_code'].astype(str)
    
    if gdf.crs is not None and gdf.crs.to_epsg() != 4326:
        gdf = gdf.to_crs(epsg=4326)
    elif gdf.crs is None:
        gdf.set_crs(epsg=4326, inplace=True)
    return gdf


def clean_sa4_boundaries(file_path):
    # Clean all SA4 Regions
    sa4_gdf = gpd.read_file(file_path)  
    sa4_gdf = sa4_gdf[["SA4_CODE21", "SA4_NAME21", "geometry"]].rename(columns={
        "SA4_CODE21": "sa4_code",
        "SA4_NAME21": "sa4_name"
    })
    sa4_gdf["sa4_code"] = sa4_gdf["sa4_code"].astype(str)

    # Filter out rows with missing geometry
    sa4_gdf = sa4_gdf[sa4_gdf['geometry'].notnull()].copy()

    
    # Ensure CRS is WGS84
    if sa4_gdf.crs is None or sa4_gdf.crs.to_epsg() != 4326:
        sa4_gdf = sa4_gdf.to_crs(epsg=4326)
    elif sa4_gdf.crs is None:
        sa4_gdf.set_crs(epsg=4326, inplace=True)
    return sa4_gdf






# function to get points of interest within a bounding box
def get_geometry_bbox(geometry):
    """get the bounding box coordinates of a geometry"""
    return geometry.bounds  # (min_lon, min_lat, max_lon, max_lat)

# function to check if a point is within a polygon
def point_in_polygon(point, polygon):
    """check if a point is within a polygon"""
    return polygon.contains(point)

# get_poi_in_bbox(min_lon, min_lat, max_lon, max_lat)
def get_poi_in_bbox(min_lon, min_lat, max_lon, max_lat):
    """get points of interest within a bounding box from nsw poi api"""
    base_url = "https://maps.six.nsw.gov.au/arcgis/rest/services/public/NSW_POI/MapServer/0/query"
    
    params = {
        'where': '1=1',
        'outFields': '*',
        'geometry': f"{min_lon},{min_lat},{max_lon},{max_lat}",
        'geometryType': 'esriGeometryEnvelope',
        'inSR': '4326',
        'outSR': '4326',
        'spatialRel': 'esriSpatialRelIntersects',
        'f': 'json'
    }
    
    try:
        response = requests.get(base_url, params=params)
        response.raise_for_status()
        
        data = response.json()
        
        if 'features' not in data:
            print(f"no features found in response: {data}")
            return []
            
        return data['features']
    
    except Exception as e:
        print(f"error fetching poi data: {e}")
        return []







# process_poi_for_sa2_regions(sa2_gdf, selected_sa4s=None)
def process_poi_for_sa2_regions(sa2_gdf, selected_sa4s=None):
    """
    Process points of interest for all SA2 regions within selected SA4 regions.
    
    Parameters:
    -----------
    sa2_gdf : geopandas.GeoDataFrame
        GeoDataFrame containing SA2 region boundaries
    selected_sa4s : list, optional
        List of SA4 region names to filter by. If None, all SA2 regions are processed.
        
    Returns:
    --------
    pandas.DataFrame
        DataFrame containing points of interest with associated SA2 regions
    """
    # Filter SA2 regions by selected SA4s if provided
    if selected_sa4s and 'sa4_name' in sa2_gdf.columns:
        filtered_sa2 = sa2_gdf[sa2_gdf['sa4_name'].isin(selected_sa4s)]
    else:
        filtered_sa2 = sa2_gdf
    
    # Initialize an empty list to store all POIs
    all_pois = []
    
    # Loop through each SA2 region
    for idx, sa2_region in filtered_sa2.iterrows():
        sa2_code = sa2_region['sa2_code']
        sa2_name = sa2_region['sa2_name']
        sa2_geometry = sa2_region['geometry']
        
        print(f"Processing SA2 region: {sa2_name} ({sa2_code})")
        
        # Get the bounding box of the SA2 region
        min_lon, min_lat, max_lon, max_lat = get_geometry_bbox(sa2_geometry)
        
        # Get all POIs within the bounding box
        pois = get_poi_in_bbox(min_lon, min_lat, max_lon, max_lat)
        
        # Filter POIs to only include those within the SA2 region
        for poi in pois:
            if 'geometry' in poi and 'x' in poi['geometry'] and 'y' in poi['geometry']:
                # Create a Point from the POI coordinates
                poi_point = Point(poi['geometry']['x'], poi['geometry']['y'])
                
                # Check if the point is within the SA2 region
                if point_in_polygon(poi_point, sa2_geometry):
                    # Add SA2 information to the POI
                    poi['attributes']['sa2_code'] = sa2_code
                    poi['attributes']['sa2_name'] = sa2_name
                    
                    # Add coordinates for easier access
                    poi['attributes']['longitude'] = poi['geometry']['x']
                    poi['attributes']['latitude'] = poi['geometry']['y']
                    
                    # Add the POI to the list
                    all_pois.append(poi['attributes'])
    
    # Create a DataFrame from all POIs
    if all_pois:
        poi_df = pd.DataFrame(all_pois)
        
        # Select only the columns we need
        columns_to_keep = [
            'objectid', 'poigroup', 'poitype', 'poiname', 'poilabel',
            'sa2_code', 'sa2_name', 'longitude', 'latitude'
        ]
        existing_columns = [col for col in columns_to_keep if col in poi_df.columns]
        poi_df = poi_df[existing_columns]
        
        # Rename columns for clarity
        column_mapping = {
            'objectid': 'poi_id',
            'poigroup': 'poi_group',
            'poitype': 'poi_type',
            'poiname': 'poi_name',
            'poilabel': 'poi_label'
        }
        poi_df = poi_df.rename(columns=column_mapping)
        
        return poi_df
    else:
        print("No POIs found within any SA2 region.")
        return pd.DataFrame()





# Function to save POI data to PostgreSQL
def save_poi_to_postgresql(poi_df, engine):
    """save points of interest data to postgresql"""
    try:
        geometry = [Point(xy) for xy in zip(poi_df['longitude'], poi_df['latitude'])]
        gdf = gpd.GeoDataFrame(poi_df, geometry=geometry, crs="EPSG:4326")
        gdf = gdf.drop(['longitude', 'latitude'], axis=1)
        
        gdf.to_postgis("points_of_interest", engine, if_exists="replace", index=False)
        
        print(f"successfully saved {len(gdf)} points of interest to postgresql")
        
        with engine.begin() as conn:
            for index_name in ["idx_poi_sa2_code", "idx_poi_geometry"]:
                result = conn.execute(text(f"""
                SELECT EXISTS (
                    SELECT 1 FROM pg_indexes 
                    WHERE indexname = '{index_name}'
                )
                """))
                if not result.scalar():
                    if index_name == "idx_poi_geometry":
                        conn.execute(text(f"CREATE INDEX {index_name} ON points_of_interest USING GIST(geometry)"))
                    else:
                        conn.execute(text(f"CREATE INDEX {index_name} ON points_of_interest(sa2_code)"))
            print("added indexes to points_of_interest table")
        
        return True
    
    except Exception as e:
        print(f"error saving poi data to postgresql: {e}")
        return False






def save_cleaned_data(income_cleaned, population_cleaned, businesses_cleaned, stops_cleaned, sa2, primary, secondary, future, sa4):
    """save all cleaned data to files and postgresql"""
    # save cleaned csv datasets
    income_cleaned.to_csv("income_cleaned.csv", index=False)
    population_cleaned.to_csv("population_cleaned.csv", index=False)
    businesses_cleaned.to_csv("businesses_cleaned.csv", index=False)
    stops_cleaned.to_csv("stops_cleaned.csv", index=False)
    
    # save cleaned shapefiles
    sa2.to_file("sa2_cleaned.shp")
    sa4.to_file("sa4_cleaned.shp")
    primary.to_file("catchments_primary_cleaned.shp")
    secondary.to_file("catchments_secondary_cleaned.shp")
    future.to_file("catchments_future_cleaned.shp")
    
    try:
        print("\nsaving all datasets to postgresql...")
        engine, conn = pgconnect(CREDENTIALS_FILE)
        if engine is None:
            print("failed to connect to the database. skipping postgresql operations.")
            return
        
        # save sa2 boundaries
        with engine.begin() as conn:
            result = conn.execute(text("SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'sa2_boundaries')"))
            table_exists = result.scalar()
            
            if table_exists:
                print("sa2 boundaries table already exists in postgresql.")
                result = conn.execute(text("SELECT sa2_code FROM sa2_boundaries"))
                existing_codes = [row[0] for row in result]
                
                sa2_df = sa2.copy()
                
                for idx, row in sa2_df.iterrows():
                    sa2_code = row['sa2_code']
                    sa2_name = row['sa2_name']
                    wkt_geometry = row['geometry'].wkt
                    
                    if sa2_code in existing_codes:
                        conn.execute(text("""
                        UPDATE sa2_boundaries 
                        SET sa2_name = :sa2_name, 
                            geometry = ST_GeomFromText(:wkt_geometry, 4326)
                        WHERE sa2_code = :sa2_code
                        """), {"sa2_code": sa2_code, "sa2_name": sa2_name, "wkt_geometry": wkt_geometry})
                    else:
                        conn.execute(text("""
                        INSERT INTO sa2_boundaries (sa2_code, sa2_name, geometry)
                        VALUES (:sa2_code, :sa2_name, ST_GeomFromText(:wkt_geometry, 4326))
                        """), {"sa2_code": sa2_code, "sa2_name": sa2_name, "wkt_geometry": wkt_geometry})
                
                print("successfully updated sa2 boundaries in postgresql")
            else:
                sa2.to_postgis("sa2_boundaries", engine, if_exists="replace", index=False)
                
                with engine.begin() as conn:
                    conn.execute(text("""
                    CREATE INDEX idx_sa2_boundaries_geometry ON sa2_boundaries USING GIST(geometry);
                    CREATE INDEX idx_sa2_boundaries_sa2_code ON sa2_boundaries(sa2_code);
                    """))
                
                print("successfully saved sa2 boundaries to postgresql with indexes")
        
        # get valid sa2 codes
        valid_sa2_codes = set(sa2['sa2_code'].tolist())
        print(f"found {len(valid_sa2_codes)} valid sa2 codes in greater sydney region")


        # Insert or update SA4 boundaries in PostgreSQL
        with engine.begin() as conn:
            result = conn.execute(text("SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'sa4_boundaries')"))
            table_exists = result.scalar()
            
            if table_exists:
                print("sa4 boundaries table already exists in postgresql.")
                result = conn.execute(text("SELECT sa4_code FROM sa4_boundaries"))
                existing_codes = [row[0] for row in result]
                
                sa4_df = sa4.copy()
                
                for idx, row in sa4_df.iterrows():
                    sa4_code = row['sa4_code']
                    sa4_name = row['sa4_name']
                    wkt_geometry = row['geometry'].wkt
                    
                    if sa4_code in existing_codes:
                        conn.execute(text("""
                        UPDATE sa4_boundaries 
                        SET sa4_name = :sa4_name, 
                            geometry = ST_GeomFromText(:wkt_geometry, 4326)
                        WHERE sa4_code = :sa4_code
                        """), {"sa4_code": sa4_code, "sa4_name": sa4_name, "wkt_geometry": wkt_geometry})
                    else:
                        conn.execute(text("""
                        INSERT INTO sa4_boundaries (sa4_code, sa4_name, geometry)
                        VALUES (:sa4_code, :sa4_name, ST_GeomFromText(:wkt_geometry, 4326))
                        """), {"sa4_code": sa4_code, "sa4_name": sa4_name, "wkt_geometry": wkt_geometry})
                
                print("successfully updated sa4 boundaries in postgresql")
            
            else:
                sa4.to_postgis("sa4_boundaries", engine, if_exists="replace", index=False)
                
                with engine.begin() as conn:
                    conn.execute(text("""
                    CREATE INDEX IF NOT EXISTS idx_sa4_boundaries_geometry ON sa4_boundaries USING GIST(geometry);
                    CREATE INDEX IF NOT EXISTS idx_sa4_boundaries_sa4_code ON sa4_boundaries(sa4_code);
                    """))
                
                print("successfully saved sa4 boundaries to postgresql with indexes")
                
        
        valid_sa4_codes = set(sa4['sa4_code'].tolist())
        print(f"found {len(valid_sa4_codes)} valid sa4 codes in greater sydney region")

        # save income data
        income_filtered = income_cleaned[income_cleaned['sa2_code'].isin(valid_sa2_codes)].copy()
        print(f"filtered income data from {len(income_cleaned)} to {len(income_filtered)} records (greater sydney only)")
        
        income_filtered.to_sql("income", engine, if_exists="replace", index=False, dtype={"sa2_code": Text})
        with engine.begin() as conn:
            result = conn.execute(text("""
            SELECT EXISTS (
                SELECT 1 FROM pg_indexes 
                WHERE indexname = 'idx_income_sa2_code'
            )
            """))
            if not result.scalar():
                conn.execute(text("CREATE INDEX idx_income_sa2_code ON income(sa2_code)"))
        print("successfully saved income data to postgresql")
        
        # save population data
        population_filtered = population_cleaned[population_cleaned['sa2_code'].isin(valid_sa2_codes)].copy()
        print(f"filtered population data from {len(population_cleaned)} to {len(population_filtered)} records (greater sydney only)")
        
        population_filtered.to_sql("population", engine, if_exists="replace", index=False, dtype={"sa2_code": Text})
        with engine.begin() as conn:
            result = conn.execute(text("""
            SELECT EXISTS (
                SELECT 1 FROM pg_indexes 
                WHERE indexname = 'idx_population_sa2_code'
            )
            """))
            if not result.scalar():
                conn.execute(text("CREATE INDEX idx_population_sa2_code ON population(sa2_code)"))
        print("successfully saved population data to postgresql")
        
        # save businesses data
        businesses_filtered = businesses_cleaned[businesses_cleaned['sa2_code'].isin(valid_sa2_codes)].copy()
        print(f"filtered businesses data from {len(businesses_cleaned)} to {len(businesses_filtered)} records (greater sydney only)")
        
        businesses_filtered.to_sql("businesses", engine, if_exists="replace", index=False, dtype={"sa2_code": Text})
        with engine.begin() as conn:
            for index_name in ["idx_businesses_sa2_code", "idx_businesses_industry_code"]:
                result = conn.execute(text(f"""
                SELECT EXISTS (
                    SELECT 1 FROM pg_indexes 
                    WHERE indexname = '{index_name}'
                )
                """))
                if not result.scalar():
                    if index_name == "idx_businesses_sa2_code":
                        conn.execute(text(f"CREATE INDEX {index_name} ON businesses(sa2_code)"))
                    else:
                        conn.execute(text(f"CREATE INDEX {index_name} ON businesses(industry_code)"))
        print("successfully saved businesses data to postgresql")
        
        # save stops data
        stops_gdf = gpd.GeoDataFrame(
            stops_cleaned, 
            geometry=gpd.points_from_xy(stops_cleaned.stop_lon, stops_cleaned.stop_lat),
            crs="EPSG:4326"
        )
        stops_gdf = stops_gdf.drop(['stop_lat', 'stop_lon'], axis=1)
        stops_gdf.to_postgis("stops", engine, if_exists="replace", index=False)
        with engine.begin() as conn:
            for index_name in ["idx_stops_geometry", "idx_stops_stop_id"]:
                result = conn.execute(text(f"""
                SELECT EXISTS (
                    SELECT 1 FROM pg_indexes 
                    WHERE indexname = '{index_name}'
                )
                """))
                if not result.scalar():
                    if index_name == "idx_stops_geometry":
                        conn.execute(text(f"CREATE INDEX {index_name} ON stops USING GIST(geometry)"))
                    else:
                        conn.execute(text(f"CREATE INDEX {index_name} ON stops(stop_id)"))
        print("successfully saved stops data to postgresql")
        
        # save school catchments
        primary.to_postgis("primary_catchments", engine, if_exists="replace", index=False)
        with engine.begin() as conn:
            result = conn.execute(text("""
            SELECT EXISTS (
                SELECT 1 FROM pg_indexes 
                WHERE indexname = 'idx_primary_catchments_geometry'
            )
            """))
            if not result.scalar():
                conn.execute(text("CREATE INDEX idx_primary_catchments_geometry ON primary_catchments USING GIST(geometry)"))
        print("successfully saved primary school catchments to postgresql")
        
        secondary.to_postgis("secondary_catchments", engine, if_exists="replace", index=False)
        with engine.begin() as conn:
            result = conn.execute(text("""
            SELECT EXISTS (
                SELECT 1 FROM pg_indexes 
                WHERE indexname = 'idx_secondary_catchments_geometry'
            )
            """))
            if not result.scalar():
                conn.execute(text("CREATE INDEX idx_secondary_catchments_geometry ON secondary_catchments USING GIST(geometry)"))
        print("successfully saved secondary school catchments to postgresql")
        
        future.to_postgis("future_catchments", engine, if_exists="replace", index=False)
        with engine.begin() as conn:
            result = conn.execute(text("""
            SELECT EXISTS (
                SELECT 1 FROM pg_indexes 
                WHERE indexname = 'idx_future_catchments_geometry'
            )
            """))
            if not result.scalar():
                conn.execute(text("CREATE INDEX idx_future_catchments_geometry ON future_catchments USING GIST(geometry)"))
        print("successfully saved future school catchments to postgresql")
        
        print("\nall datasets successfully saved to postgresql with proper indexing")
        
    except Exception as e:
        print(f"error saving data to postgresql: {e}")






def process_poi_data():
    """process points of interest data for sa2 regions and save to postgresql"""
    try:
        print("\nprocessing points of interest data...")
        
        print("loading sa2 boundaries...")
        sa2_boundaries = gpd.read_file("sa2_cleaned.shp")
        
        selected_sa4s = [
            "Sydney - Baulkham Hills and Hawkesbury",
            "Sydney - Inner West",
            "Sydney - Eastern Suburbs"
        ]
        
        print(f"processing poi data for selected sa4 regions: {', '.join(selected_sa4s)}")
        poi_df = process_poi_for_sa2_regions(sa2_boundaries, selected_sa4s)
        
        if not poi_df.empty:
            print(f"found {len(poi_df)} points of interest across all sa2 regions")
            
            print("\nsample poi data:")
            print(poi_df.head(5))
            
            poi_df.to_csv("points_of_interest.csv", index=False)
            print("saved poi data to csv")
            
            engine, conn = pgconnect(CREDENTIALS_FILE)
            if engine is None:
                print("failed to connect to the database. skipping postgresql operations.")
                return
                
            if save_poi_to_postgresql(poi_df, engine):
                print("poi data successfully processed and saved.")
            else:
                print("failed to save poi data to postgresql.")
        else:
            print("no poi data to save.")
    
    except Exception as e:
        print(f"error processing poi data: {e}")






def main():
    """main function to execute the data processing workflow"""
    print("loading csv datasets...")
    warnings.filterwarnings('ignore')
    try:
        # load and clean all datasets
        income = pd.read_csv("Income.csv")
        population = pd.read_csv("Population.csv")
        businesses = pd.read_csv("Businesses.csv")
        stops = pd.read_csv("stops.csv")
        
        income_cleaned = clean_income(income)
        population_cleaned = clean_population(population)
        businesses_cleaned = clean_businesses(businesses)
        stops_cleaned = clean_stops(stops)
        print("csvs loaded and cleaned.")
        
        print("loading shapefiles...")
        sa2 = clean_sa2_boundaries("SA2_2021_AUST_GDA2020.shp")
        print("sa2 shapefile loaded.")

        sa4 = clean_sa4_boundaries("SA4_2021_AUST_GDA94.shp")
        print("sa4 shapefile loaded.")
        
        
        primary = clean_catchments("./catchments/catchments_primary.shp")
        print("primary catchments loaded.")
        
        secondary = clean_catchments("./catchments/catchments_secondary.shp")
        print("secondary catchments loaded.")
        
        future = clean_catchments("./catchments/catchments_future.shp")
        print("future catchments loaded.")
        
        print("all datasets cleaned and ready for use.")
        print("-" * 50)
        
        # display sample data
        print("\nsample income data:")
        print(income_cleaned.head(3))
        
        print("\nsample population data:")
        print(population_cleaned.head(3))
        
        print("\nsample business data:")
        print(businesses_cleaned.head(3))
        
        print("\nsample stops data:")
        print(stops_cleaned.head(3))
        
        print("\nsa2 regions:")
        print(sa2[["sa2_code", "sa2_name"]].head(3))

        print("\nsa4 regions:")
        print(sa4[["sa4_code", "sa4_name"]].head(3))
        
        # save cleaned data to files and postgresql
        save_cleaned_data(income_cleaned, population_cleaned, businesses_cleaned, stops_cleaned, sa2, primary, secondary, future , sa4)
        
        # process points of interest data
        process_poi_data()

        print("Done!!")
        
    except Exception as e:
        print(f"error in main workflow: {e}")


if __name__ == "__main__":
    main()


















try:
    print("\nReading Entries from PostgreSQL with read_sql_query...\n")
    engine, conn = pgconnect(CREDENTIALS_FILE)
    if engine is None:
        print("Failed to connect to the database. Skipping PostgreSQL operations.\n")
    else:
        query = '''
        SELECT sa2.sa2_name, sa2.sa2_code, ST_AsText(ST_Centroid(sa2.geometry)) AS Coordinates
        FROM sa2_boundaries sa2
        JOIN sa4_boundaries sa4
          ON ST_Within(sa2.geometry, sa4.geometry)
        WHERE sa4.sa4_name = 'Sydney - Inner West';
        '''

        # Run query and load result into a DataFrame
        df = pd.read_sql_query(query, con=engine)

        # Optionally show result as text-based table
        print("SA2 Regions in Inner-west:")
        print()
        print(df.to_string(index=False))

except Exception as e:
    print("Error during PostgreSQL operation:", e)





try:
    print("\nReading Entries from PostgreSQL with read_sql_query...\n")
    engine, conn = pgconnect(CREDENTIALS_FILE)
    if engine is None:
        print("Failed to connect to the database. Skipping PostgreSQL operations.\n")
    else:
        query = '''
        WITH sa2_filtered AS (
          SELECT sa2.*
          FROM sa2_boundaries sa2
          JOIN sa4_boundaries sa4
            ON ST_Within(sa2.geometry, sa4.geometry)
          WHERE sa4.sa4_name = 'Sydney - Inner West'
        ),
        stops_count AS (
          SELECT sa2_name, COUNT(*) AS stop_count
          FROM stops s
          JOIN sa2_boundaries sa2 ON ST_Within(s.geometry, sa2.geometry)
          GROUP BY sa2_name
        ),
        poi_count AS (
          SELECT sa2_name, COUNT(*) AS poi_count
          FROM points_of_interest
          GROUP BY sa2_name
        ),
        business_sum AS (
          SELECT sa2_name, SUM(total_businesses) AS business_total
          FROM businesses
          GROUP BY sa2_name
        ),
        population_data AS (
          SELECT sa2_name, MAX(total_population) AS population
          FROM population
          GROUP BY sa2_name
        )
        
        SELECT 
          sa2.sa2_name,
          COALESCE(sc.stop_count, 0) AS stops,
          COALESCE(p.population, 0) AS population,
          COALESCE(b.business_total, 0) AS business,
          COALESCE(pc.poi_count, 0) AS poi
        FROM sa2_filtered sa2
        LEFT JOIN stops_count sc ON sa2.sa2_name = sc.sa2_name
        LEFT JOIN poi_count pc ON sa2.sa2_name = pc.sa2_name
        LEFT JOIN business_sum b ON sa2.sa2_name = b.sa2_name
        LEFT JOIN population_data p ON sa2.sa2_name = p.sa2_name
        WHERE population >= 100;
        '''

        # Run query and load result into a DataFrame
        df = pd.read_sql_query(query, con=engine)

        # Optionally show result as text-based table
        print("Total Stops, Points of Interest, Businesses, population in each region: ")
        print()
        print(df.to_string(index=False))

except Exception as e:
    print("Error during PostgreSQL operation:", e)





try:
    print("\nReading Entries from PostgreSQL with read_sql_query...\n")
    engine, conn = pgconnect(CREDENTIALS_FILE)
    if engine is None:
        print("Failed to connect to the database. Skipping PostgreSQL operations.\n")
    else:
        query = '''
        WITH base_data AS (
          WITH sa2_filtered AS (
            SELECT sa2.*
            FROM sa2_boundaries sa2
            JOIN sa4_boundaries sa4 ON ST_Within(sa2.geometry, sa4.geometry)
            WHERE sa4.sa4_name = 'Sydney - Inner West'
          ),
          stops_count AS (
            SELECT sa2_name, COUNT(*) AS stops
            FROM stops s
            JOIN sa2_boundaries sa2 ON ST_Within(s.geometry, sa2.geometry)
            GROUP BY sa2_name
          ),
          poi_count AS (
            SELECT sa2_name, COUNT(*) AS poi
            FROM points_of_interest
            GROUP BY sa2_name
          ),
          business_sum AS (
            SELECT sa2_name, SUM(total_businesses) AS business
            FROM businesses
            GROUP BY sa2_name
          ),
          population_data AS (
            SELECT sa2_name, MAX(total_population) AS population
            FROM population
            GROUP BY sa2_name
          )
          SELECT 
            sa2.sa2_name,
            COALESCE(sc.stops, 0) AS stops,
            COALESCE(p.population, 0) AS population,
            COALESCE(b.business, 0) AS business,
            COALESCE(pc.poi, 0) AS poi
          FROM sa2_filtered sa2
          LEFT JOIN stops_count sc ON sa2.sa2_name = sc.sa2_name
          LEFT JOIN poi_count pc ON sa2.sa2_name = pc.sa2_name
          LEFT JOIN business_sum b ON sa2.sa2_name = b.sa2_name
          LEFT JOIN population_data p ON sa2.sa2_name = p.sa2_name
          WHERE population >= 100
        ),
        z_scores AS (
          SELECT *,
            (business - AVG(business) OVER()) / NULLIF(STDDEV_POP(business) OVER(), 0) AS z_business,
            (stops - AVG(stops) OVER()) / NULLIF(STDDEV_POP(stops) OVER(), 0) AS z_stops,
            (poi - AVG(poi) OVER()) / NULLIF(STDDEV_POP(poi) OVER(), 0) AS z_poi
          FROM base_data
          WHERE population >= 100 -- Optional: exclude underpopulated regions
        ),
        sigmoid_scores AS (
          -- Step 3: Apply sigmoid function: 1 / (1 + exp(-z))
          SELECT *,
            1 / (1 + EXP(-z_business)) AS s_business,
            1 / (1 + EXP(-z_stops)) AS s_stops,
            1 / (1 + EXP(-z_poi)) AS s_poi,
            1 / (1 + EXP(-(z_business + z_stops + z_poi))) AS final_score
          FROM z_scores
        )
        
        SELECT 
          sa2_name,
          ROUND(s_business, 3) AS sigmoid_business,
          ROUND(s_stops, 3) AS sigmoid_stops,
          ROUND(s_poi, 3) AS sigmoid_poi,
          ROUND(final_score, 3) AS well_resourced_score
        FROM sigmoid_scores
        ORDER BY final_score DESC;
        '''

        # Run query and load result into a DataFrame
        df = pd.read_sql_query(query, con=engine)

        # Optionally show result as text-based table
        print("Sigmaoid Function and Well_resourced score for each region:")
        print()
        print(df.to_string(index=False))

except Exception as e:
    print("Error during PostgreSQL operation:", e)








try:
    print("\nReading Entries from PostgreSQL with read_sql_query...\n")
    engine, conn = pgconnect(CREDENTIALS_FILE)
    if engine is None:
        print("Failed to connect to the database. Skipping PostgreSQL operations.\n")
    else:
        query = '''
        SELECT sa2.sa2_name, sa2.sa2_code, ST_AsText(ST_Centroid(sa2.geometry)) AS Coordinates
        FROM sa2_boundaries sa2
        JOIN sa4_boundaries sa4
          ON ST_Within(sa2.geometry, sa4.geometry)
        WHERE sa4.sa4_name = 'Sydney - Eastern Suburbs';
        '''

        # Run query and load result into a DataFrame
        df = pd.read_sql_query(query, con=engine)

        # Optionally show result as text-based table
        print("SA2 Regions in Eastern Suburbs: ")
        print()
        print(df.to_string(index=False))

except Exception as e:
    print("Error during PostgreSQL operation:", e)


try:
    print("\nReading Entries from PostgreSQL with read_sql_query...\n")
    engine, conn = pgconnect(CREDENTIALS_FILE)
    if engine is None:
        print("Failed to connect to the database. Skipping PostgreSQL operations.\n")
    else:
        query = '''
        WITH sa2_filtered AS (
          SELECT sa2.*
          FROM sa2_boundaries sa2
          JOIN sa4_boundaries sa4
            ON ST_Within(sa2.geometry, sa4.geometry)
          WHERE sa4.sa4_name = 'Sydney - Eastern Suburbs'
        ),
        stops_count AS (
          SELECT sa2_name, COUNT(*) AS stop_count
          FROM stops s
          JOIN sa2_boundaries sa2 ON ST_Within(s.geometry, sa2.geometry)
          GROUP BY sa2_name
        ),
        poi_count AS (
          SELECT sa2_name, COUNT(*) AS poi_count
          FROM points_of_interest
          GROUP BY sa2_name
        ),
        business_sum AS (
          SELECT sa2_name, SUM(total_businesses) AS business_total
          FROM businesses
          GROUP BY sa2_name
        ),
        population_data AS (
          SELECT sa2_name, MAX(total_population) AS population
          FROM population
          GROUP BY sa2_name
        )
        
        SELECT 
          sa2.sa2_name,
          COALESCE(sc.stop_count, 0) AS stops,
          COALESCE(p.population, 0) AS population,
          COALESCE(b.business_total, 0) AS business,
          COALESCE(pc.poi_count, 0) AS poi
        FROM sa2_filtered sa2
        LEFT JOIN stops_count sc ON sa2.sa2_name = sc.sa2_name
        LEFT JOIN poi_count pc ON sa2.sa2_name = pc.sa2_name
        LEFT JOIN business_sum b ON sa2.sa2_name = b.sa2_name
        LEFT JOIN population_data p ON sa2.sa2_name = p.sa2_name
        WHERE population >= 100;
        '''

        # Run query and load result into a DataFrame
        df = pd.read_sql_query(query, con=engine)

        # Optionally show result as text-based table
        print("Total Stops, Points of Interest, Businesses, population in each region: ")
        print()
        print(df.to_string(index=False))

except Exception as e:
    print("Error during PostgreSQL operation:", e)


try:
    print("\nReading Entries from PostgreSQL with read_sql_query...\n")
    engine, conn = pgconnect(CREDENTIALS_FILE)
    if engine is None:
        print("Failed to connect to the database. Skipping PostgreSQL operations.\n")
    else:
        query = '''
        WITH base_data AS (
          WITH sa2_filtered AS (
            SELECT sa2.*
            FROM sa2_boundaries sa2
            JOIN sa4_boundaries sa4 ON ST_Within(sa2.geometry, sa4.geometry)
            WHERE sa4.sa4_name = 'Sydney - Eastern Suburbs'
            ),
          stops_count AS (
            SELECT sa2_name, COUNT(*) AS stops
            FROM stops s
            JOIN sa2_boundaries sa2 ON ST_Within(s.geometry, sa2.geometry)
            GROUP BY sa2_name
          ),
          poi_count AS (
            SELECT sa2_name, COUNT(*) AS poi
            FROM points_of_interest
            GROUP BY sa2_name
          ),
          business_sum AS (
            SELECT sa2_name, SUM(total_businesses) AS business
            FROM businesses
            GROUP BY sa2_name
          ),
          population_data AS (
            SELECT sa2_name, MAX(total_population) AS population
            FROM population
            GROUP BY sa2_name
          )
          SELECT 
            sa2.sa2_name,
            COALESCE(sc.stops, 0) AS stops,
            COALESCE(p.population, 0) AS population,
            COALESCE(b.business, 0) AS business,
            COALESCE(pc.poi, 0) AS poi
          FROM sa2_filtered sa2
          LEFT JOIN stops_count sc ON sa2.sa2_name = sc.sa2_name
          LEFT JOIN poi_count pc ON sa2.sa2_name = pc.sa2_name
          LEFT JOIN business_sum b ON sa2.sa2_name = b.sa2_name
          LEFT JOIN population_data p ON sa2.sa2_name = p.sa2_name
          WHERE population >= 100
        ),
        z_scores AS (
          SELECT *,
            (business - AVG(business) OVER()) / NULLIF(STDDEV_POP(business) OVER(), 0) AS z_business,
            (stops - AVG(stops) OVER()) / NULLIF(STDDEV_POP(stops) OVER(), 0) AS z_stops,
            (poi - AVG(poi) OVER()) / NULLIF(STDDEV_POP(poi) OVER(), 0) AS z_poi
          FROM base_data
          WHERE population >= 100 -- Optional: exclude underpopulated regions
        ),
        sigmoid_scores AS (
          -- Step 3: Apply sigmoid function: 1 / (1 + exp(-z))
          SELECT *,
            1 / (1 + EXP(-z_business)) AS s_business,
            1 / (1 + EXP(-z_stops)) AS s_stops,
            1 / (1 + EXP(-z_poi)) AS s_poi,
            1 / (1 + EXP(-(z_business + z_stops + z_poi))) AS final_score
          FROM z_scores
        )
        
        SELECT 
          sa2_name,
          ROUND(s_business, 3) AS sigmoid_business,
          ROUND(s_stops, 3) AS sigmoid_stops,
          ROUND(s_poi, 3) AS sigmoid_poi,
          ROUND(final_score, 3) AS well_resourced_score
        FROM sigmoid_scores
        ORDER BY final_score DESC;
        '''

        # Run query and load result into a DataFrame
        df = pd.read_sql_query(query, con=engine)

        # Optionally show result as text-based table
        print("Sigmaoid Function and Well_resourced score for each region:")
        print()
        print(df.to_string(index=False))

except Exception as e:
    print("Error during PostgreSQL operation:", e)





try:
    print("\nReading Entries from PostgreSQL with read_sql_query...\n")
    engine, conn = pgconnect(CREDENTIALS_FILE)
    if engine is None:
        print("Failed to connect to the database. Skipping PostgreSQL operations.\n")
    else:
        query = '''
        SELECT sa2.sa2_name, sa2.sa2_code, ST_AsText(ST_Centroid(sa2.geometry)) AS Coordinates
        FROM sa2_boundaries sa2
        JOIN sa4_boundaries sa4
          ON ST_Within(sa2.geometry, sa4.geometry)
        WHERE sa4.sa4_name = 'Sydney - Eastern Suburbs';
        '''

        # Run query and load result into a DataFrame
        df = pd.read_sql_query(query, con=engine)

        # Optionally show result as text-based table
        print("SA2 Regions in Baulkham Hills and Hawkesbury: ")
        print()
        print(df.to_string(index=False))

except Exception as e:
    print("Error during PostgreSQL operation:", e)


try:
    print("\nReading Entries from PostgreSQL with read_sql_query...\n")
    engine, conn = pgconnect(CREDENTIALS_FILE)
    if engine is None:
        print("Failed to connect to the database. Skipping PostgreSQL operations.\n")
    else:
        query = '''
        WITH sa2_filtered AS (
          SELECT sa2.*
          FROM sa2_boundaries sa2
          JOIN sa4_boundaries sa4
            ON ST_Within(sa2.geometry, sa4.geometry)
          WHERE sa4.sa4_name = 'Sydney - Baulkham Hills and Hawkesbury'
        ),
        stops_count AS (
          SELECT sa2_name, COUNT(*) AS stop_count
          FROM stops s
          JOIN sa2_boundaries sa2 ON ST_Within(s.geometry, sa2.geometry)
          GROUP BY sa2_name
        ),
        poi_count AS (
          SELECT sa2_name, COUNT(*) AS poi_count
          FROM points_of_interest
          GROUP BY sa2_name
        ),
        business_sum AS (
          SELECT sa2_name, SUM(total_businesses) AS business_total
          FROM businesses
          GROUP BY sa2_name
        ),
        population_data AS (
          SELECT sa2_name, MAX(total_population) AS population
          FROM population
          GROUP BY sa2_name

        )
        
        SELECT 
          sa2.sa2_name,
          COALESCE(sc.stop_count, 0) AS stops,
          COALESCE(p.population, 0) AS population,
          COALESCE(b.business_total, 0) AS business,
          COALESCE(pc.poi_count, 0) AS poi
        FROM sa2_filtered sa2
        LEFT JOIN stops_count sc ON sa2.sa2_name = sc.sa2_name
        LEFT JOIN poi_count pc ON sa2.sa2_name = pc.sa2_name
        LEFT JOIN business_sum b ON sa2.sa2_name = b.sa2_name
        LEFT JOIN population_data p ON sa2.sa2_name = p.sa2_name
        WHERE population >= 100;
        '''

        # Run query and load result into a DataFrame
        df = pd.read_sql_query(query, con=engine)

        # Optionally show result as text-based table
        print("Total Stops, Points of Interest, Businesses, population in each region: ")
        print()
        print(df.to_string(index=False))

except Exception as e:
    print("Error during PostgreSQL operation:", e)


try:
    print("\nReading Entries from PostgreSQL with read_sql_query...\n")
    engine, conn = pgconnect(CREDENTIALS_FILE)
    if engine is None:
        print("Failed to connect to the database. Skipping PostgreSQL operations.\n")
    else:
        query = '''
        WITH base_data AS (
          WITH sa2_filtered AS (
            SELECT sa2.*
            FROM sa2_boundaries sa2
            JOIN sa4_boundaries sa4 ON ST_Within(sa2.geometry, sa4.geometry)
            WHERE sa4.sa4_name = 'Sydney - Baulkham Hills and Hawkesbury'
            ),
          stops_count AS (
            SELECT sa2_name, COUNT(*) AS stops
            FROM stops s
            JOIN sa2_boundaries sa2 ON ST_Within(s.geometry, sa2.geometry)
            GROUP BY sa2_name
          ),
          poi_count AS (
            SELECT sa2_name, COUNT(*) AS poi
            FROM points_of_interest
            GROUP BY sa2_name
          ),
          business_sum AS (
            SELECT sa2_name, SUM(total_businesses) AS business
            FROM businesses
            GROUP BY sa2_name
          ),
          population_data AS (
            SELECT sa2_name, MAX(total_population) AS population
            FROM population
            GROUP BY sa2_name
          )
          SELECT 
            sa2.sa2_name,
            COALESCE(sc.stops, 0) AS stops,
            COALESCE(p.population, 0) AS population,
            COALESCE(b.business, 0) AS business,
            COALESCE(pc.poi, 0) AS poi
          FROM sa2_filtered sa2
          LEFT JOIN stops_count sc ON sa2.sa2_name = sc.sa2_name
          LEFT JOIN poi_count pc ON sa2.sa2_name = pc.sa2_name
          LEFT JOIN business_sum b ON sa2.sa2_name = b.sa2_name
          LEFT JOIN population_data p ON sa2.sa2_name = p.sa2_name
          WHERE population >= 100
        ),
        z_scores AS (
          SELECT *,
            (business - AVG(business) OVER()) / NULLIF(STDDEV_POP(business) OVER(), 0) AS z_business,
            (stops - AVG(stops) OVER()) / NULLIF(STDDEV_POP(stops) OVER(), 0) AS z_stops,
            (poi - AVG(poi) OVER()) / NULLIF(STDDEV_POP(poi) OVER(), 0) AS z_poi
          FROM base_data
          WHERE population >= 100 -- Optional: exclude underpopulated regions
        ),
        sigmoid_scores AS (
          -- Step 3: Apply sigmoid function: 1 / (1 + exp(-z))
          SELECT *,
            1 / (1 + EXP(-z_business)) AS s_business,
            1 / (1 + EXP(-z_stops)) AS s_stops,
            1 / (1 + EXP(-z_poi)) AS s_poi,
            1 / (1 + EXP(-(z_business + z_stops + z_poi))) AS final_score
          FROM z_scores
        )
        
        SELECT 
          sa2_name,
          ROUND(s_business, 3) AS sigmoid_business,
          ROUND(s_stops, 3) AS sigmoid_stops,
          ROUND(s_poi, 3) AS sigmoid_poi,
          ROUND(final_score, 3) AS well_resourced_score
        FROM sigmoid_scores
        ORDER BY final_score DESC;
        '''

        # Run query and load result into a DataFrame
        df = pd.read_sql_query(query, con=engine)

        # Optionally show result as text-based table
        print("Sigmaoid Function and Well_resourced score for each region:")
        print()
        print(df.to_string(index=False))

except Exception as e:
    print("Error during PostgreSQL operation:", e)
